\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{intro}{{1}{1}{Introduction}{section.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Motivation}{2}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Present situation}{2}{subsection.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Examples of vision and language navigation (VLN) tasks.\relax }}{3}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{image01}{{1}{3}{Examples of vision and language navigation (VLN) tasks.\relax }{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Examples of the keywords kitchen, hallway, sitting area, couch of the text instruction and the target features of the visual information have a certain corresponding relationship.\relax }}{3}{figure.caption.2}\protected@file@percent }
\newlabel{image02}{{2}{3}{Examples of the keywords kitchen, hallway, sitting area, couch of the text instruction and the target features of the visual information have a certain corresponding relationship.\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Our discovering}{3}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Our method brief introduction}{3}{subsection.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Schema of the proposed architecture for VLN. The input instruction is vision, instruction and trajectory. The KIM-Net consists of Key information match module, Cross-model guide module and Self-calibration module.\relax }}{4}{figure.caption.3}\protected@file@percent }
\newlabel{image03}{{3}{4}{Schema of the proposed architecture for VLN. The input instruction is vision, instruction and trajectory. The KIM-Net consists of Key information match module, Cross-model guide module and Self-calibration module.\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Model Design}{4}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Review of target detection component}{4}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Review of entity abstraction component}{4}{subsection.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Schema of the proposed architecture for Yolo.\relax }}{5}{figure.caption.4}\protected@file@percent }
\newlabel{image04}{{4}{5}{Schema of the proposed architecture for Yolo.\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Examples of instruction for navigation. We use entity abstract components to extract different types of subjects (streets, restaurants, etc.) and number them in the order of occurrence of sentences.\relax }}{5}{figure.caption.5}\protected@file@percent }
\newlabel{image05}{{5}{5}{Examples of instruction for navigation. We use entity abstract components to extract different types of subjects (streets, restaurants, etc.) and number them in the order of occurrence of sentences.\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Vision and instruction matching module}{5}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Track and instruction matching module}{6}{subsubsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}Action prediction module}{6}{subsubsection.3.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Examples of navigation trajectory. The path is rasterized and written into the memory image.\relax }}{7}{figure.caption.6}\protected@file@percent }
\newlabel{image06}{{6}{7}{Examples of navigation trajectory. The path is rasterized and written into the memory image.\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Learning Detail}{7}{subsection.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiments}{7}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Experimental settings}{7}{subsection.4.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces The ablation study of our architecture on the R2R validation group and our baseline model is the Speaker-Follower model. When the key information matching module and the trajectory self-correction module are added, the effect of the whole model is better.\relax }}{8}{table.caption.7}\protected@file@percent }
\newlabel{table_1}{{1}{8}{The ablation study of our architecture on the R2R validation group and our baseline model is the Speaker-Follower model. When the key information matching module and the trajectory self-correction module are added, the effect of the whole model is better.\relax }{table.caption.7}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Comparison of the-test-unseen set.\relax }}{8}{table.caption.8}\protected@file@percent }
\newlabel{table_2}{{2}{8}{Comparison of the-test-unseen set.\relax }{table.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Ablation study}{8}{subsection.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces  Comparison of performance on the different condition: (a) Validation Seen, (b) Validation Unseen, and (c) Test Unseen.\relax }}{9}{figure.caption.9}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Validation Seen}}}{9}{figure.caption.9}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Validation Unseen}}}{9}{figure.caption.9}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Test Unseen}}}{9}{figure.caption.9}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Comparison of the Test Unseen Set.\relax }}{9}{table.caption.11}\protected@file@percent }
\newlabel{table_3}{{3}{9}{Comparison of the Test Unseen Set.\relax }{table.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Comparison of performance on the different weight of Scoring module. The best result is approximately obtained when the is equal to 0.75.\relax }}{9}{figure.caption.10}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Related work}{9}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{9}{section.6}\protected@file@percent }
\bibstyle{ieeetr}
\bibdata{coling}
